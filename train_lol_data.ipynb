{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "import os\n",
    "import wget\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download census-income dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration PDJ107--riot-data-361ab84a17fdf47e\n",
      "Reusing dataset csv (/opt/ml/.cache/huggingface/datasets/csv/PDJ107--riot-data-361ab84a17fdf47e/0.0.0/6b9057d9e23d9d8a2f05b985917a0da84d70c5dae3d22ddd8a3f22fb01c69d9e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed492353bc948e69b2d466195a5b2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\"train\": \"train.csv\", \"validation\": \"validation.csv\", \"test\":\"test.csv\"}\n",
    "dataset = load_dataset(\"PDJ107/riot-data\", data_files=data_files, revision='cgm_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].to_pandas()\n",
    "train = train.drop(['_matchId'], axis=1)\n",
    "train['Set'] = 'train'\n",
    "valid = dataset['validation'].to_pandas()\n",
    "valid = valid.drop(['_matchId'], axis=1)\n",
    "valid['Set'] = 'valid'\n",
    "test = dataset['test'].to_pandas()\n",
    "test = test.drop(['_matchId'], axis=1)\n",
    "test['Set'] = 'test'\n",
    "\n",
    "train = pd.concat([train, valid, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalMinionsKilled_0_s</th>\n",
       "      <th>wardsPlaced_0_s</th>\n",
       "      <th>damageDealtToObjectives_0_s</th>\n",
       "      <th>turretKills_0_s</th>\n",
       "      <th>physicalDamageTaken_0_s</th>\n",
       "      <th>totalDamageDealt_0_s</th>\n",
       "      <th>assists_0_s</th>\n",
       "      <th>damageDealtToBuildings_0_s</th>\n",
       "      <th>neutralMinionsKilled_0_s</th>\n",
       "      <th>physicalDamageDealtToChampions_0_s</th>\n",
       "      <th>...</th>\n",
       "      <th>magicDamageDealt_9_s</th>\n",
       "      <th>damageSelfMitigated_9_s</th>\n",
       "      <th>damageDealtToTurrets_9_s</th>\n",
       "      <th>turretsLost_9_s</th>\n",
       "      <th>totalTimeCCDealt_9_s</th>\n",
       "      <th>totalDamageTaken_9_s</th>\n",
       "      <th>visionWardsBoughtInGame_9_s</th>\n",
       "      <th>physicalDamageDealt_9_s</th>\n",
       "      <th>win</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.384349</td>\n",
       "      <td>0.184237</td>\n",
       "      <td>545.298076</td>\n",
       "      <td>0.124783</td>\n",
       "      <td>817.139596</td>\n",
       "      <td>6064.634538</td>\n",
       "      <td>0.178361</td>\n",
       "      <td>219.112071</td>\n",
       "      <td>1.284994</td>\n",
       "      <td>794.427927</td>\n",
       "      <td>...</td>\n",
       "      <td>663.584754</td>\n",
       "      <td>324.566879</td>\n",
       "      <td>76.928818</td>\n",
       "      <td>0.102803</td>\n",
       "      <td>10.181232</td>\n",
       "      <td>433.579509</td>\n",
       "      <td>0.153529</td>\n",
       "      <td>178.532931</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.211681</td>\n",
       "      <td>0.189883</td>\n",
       "      <td>234.133063</td>\n",
       "      <td>0.041398</td>\n",
       "      <td>323.025455</td>\n",
       "      <td>3713.142398</td>\n",
       "      <td>0.251829</td>\n",
       "      <td>92.548929</td>\n",
       "      <td>0.276442</td>\n",
       "      <td>517.771145</td>\n",
       "      <td>...</td>\n",
       "      <td>365.601654</td>\n",
       "      <td>738.315027</td>\n",
       "      <td>13.437196</td>\n",
       "      <td>0.224642</td>\n",
       "      <td>1.839656</td>\n",
       "      <td>529.999910</td>\n",
       "      <td>0.137576</td>\n",
       "      <td>151.173466</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.494377</td>\n",
       "      <td>0.323323</td>\n",
       "      <td>191.637547</td>\n",
       "      <td>0.038838</td>\n",
       "      <td>366.956800</td>\n",
       "      <td>3450.909061</td>\n",
       "      <td>0.221483</td>\n",
       "      <td>117.183927</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>126.070478</td>\n",
       "      <td>...</td>\n",
       "      <td>292.696414</td>\n",
       "      <td>523.134053</td>\n",
       "      <td>27.740439</td>\n",
       "      <td>0.152885</td>\n",
       "      <td>2.118536</td>\n",
       "      <td>516.618493</td>\n",
       "      <td>0.380332</td>\n",
       "      <td>207.602800</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.901070</td>\n",
       "      <td>0.408351</td>\n",
       "      <td>202.392028</td>\n",
       "      <td>0.043064</td>\n",
       "      <td>682.581669</td>\n",
       "      <td>3387.382600</td>\n",
       "      <td>0.352387</td>\n",
       "      <td>167.950305</td>\n",
       "      <td>0.218166</td>\n",
       "      <td>492.481169</td>\n",
       "      <td>...</td>\n",
       "      <td>1508.075176</td>\n",
       "      <td>1011.594398</td>\n",
       "      <td>34.129517</td>\n",
       "      <td>0.222025</td>\n",
       "      <td>3.620328</td>\n",
       "      <td>905.347510</td>\n",
       "      <td>0.069698</td>\n",
       "      <td>71.321709</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57446</th>\n",
       "      <td>6.556485</td>\n",
       "      <td>0.351607</td>\n",
       "      <td>250.857537</td>\n",
       "      <td>0.048551</td>\n",
       "      <td>653.756544</td>\n",
       "      <td>3793.560072</td>\n",
       "      <td>0.148246</td>\n",
       "      <td>161.581983</td>\n",
       "      <td>0.228864</td>\n",
       "      <td>383.499664</td>\n",
       "      <td>...</td>\n",
       "      <td>265.278741</td>\n",
       "      <td>209.247839</td>\n",
       "      <td>34.297628</td>\n",
       "      <td>0.183640</td>\n",
       "      <td>6.281197</td>\n",
       "      <td>399.385287</td>\n",
       "      <td>0.202918</td>\n",
       "      <td>177.018736</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57447</th>\n",
       "      <td>5.561225</td>\n",
       "      <td>0.365998</td>\n",
       "      <td>232.046061</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>501.187852</td>\n",
       "      <td>3331.827664</td>\n",
       "      <td>0.229512</td>\n",
       "      <td>119.643454</td>\n",
       "      <td>0.024977</td>\n",
       "      <td>437.746144</td>\n",
       "      <td>...</td>\n",
       "      <td>339.901641</td>\n",
       "      <td>618.165555</td>\n",
       "      <td>12.523118</td>\n",
       "      <td>0.193511</td>\n",
       "      <td>7.876048</td>\n",
       "      <td>451.764455</td>\n",
       "      <td>0.335950</td>\n",
       "      <td>288.089896</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57448</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>845.495514</td>\n",
       "      <td>207.942847</td>\n",
       "      <td>20.437388</td>\n",
       "      <td>0.172670</td>\n",
       "      <td>5.299503</td>\n",
       "      <td>526.386009</td>\n",
       "      <td>0.244624</td>\n",
       "      <td>122.823517</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57449</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57450</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>342.132089</td>\n",
       "      <td>502.376201</td>\n",
       "      <td>3.651912</td>\n",
       "      <td>0.193365</td>\n",
       "      <td>4.317972</td>\n",
       "      <td>623.992657</td>\n",
       "      <td>0.344983</td>\n",
       "      <td>210.375273</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287256 rows Ã— 352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       totalMinionsKilled_0_s  wardsPlaced_0_s  damageDealtToObjectives_0_s  \\\n",
       "0                    7.384349         0.184237                   545.298076   \n",
       "1                    6.211681         0.189883                   234.133063   \n",
       "2                    0.000000         0.000000                     0.000000   \n",
       "3                    6.494377         0.323323                   191.637547   \n",
       "4                    4.901070         0.408351                   202.392028   \n",
       "...                       ...              ...                          ...   \n",
       "57446                6.556485         0.351607                   250.857537   \n",
       "57447                5.561225         0.365998                   232.046061   \n",
       "57448                0.000000         0.000000                     0.000000   \n",
       "57449                0.000000         0.000000                     0.000000   \n",
       "57450                0.000000         0.000000                     0.000000   \n",
       "\n",
       "       turretKills_0_s  physicalDamageTaken_0_s  totalDamageDealt_0_s  \\\n",
       "0             0.124783               817.139596           6064.634538   \n",
       "1             0.041398               323.025455           3713.142398   \n",
       "2             0.000000                 0.000000              0.000000   \n",
       "3             0.038838               366.956800           3450.909061   \n",
       "4             0.043064               682.581669           3387.382600   \n",
       "...                ...                      ...                   ...   \n",
       "57446         0.048551               653.756544           3793.560072   \n",
       "57447         0.034106               501.187852           3331.827664   \n",
       "57448         0.000000                 0.000000              0.000000   \n",
       "57449         0.000000                 0.000000              0.000000   \n",
       "57450         0.000000                 0.000000              0.000000   \n",
       "\n",
       "       assists_0_s  damageDealtToBuildings_0_s  neutralMinionsKilled_0_s  \\\n",
       "0         0.178361                  219.112071                  1.284994   \n",
       "1         0.251829                   92.548929                  0.276442   \n",
       "2         0.000000                    0.000000                  0.000000   \n",
       "3         0.221483                  117.183927                  0.108090   \n",
       "4         0.352387                  167.950305                  0.218166   \n",
       "...            ...                         ...                       ...   \n",
       "57446     0.148246                  161.581983                  0.228864   \n",
       "57447     0.229512                  119.643454                  0.024977   \n",
       "57448     0.000000                    0.000000                  0.000000   \n",
       "57449     0.000000                    0.000000                  0.000000   \n",
       "57450     0.000000                    0.000000                  0.000000   \n",
       "\n",
       "       physicalDamageDealtToChampions_0_s  ...  magicDamageDealt_9_s  \\\n",
       "0                              794.427927  ...            663.584754   \n",
       "1                              517.771145  ...            365.601654   \n",
       "2                                0.000000  ...              0.000000   \n",
       "3                              126.070478  ...            292.696414   \n",
       "4                              492.481169  ...           1508.075176   \n",
       "...                                   ...  ...                   ...   \n",
       "57446                          383.499664  ...            265.278741   \n",
       "57447                          437.746144  ...            339.901641   \n",
       "57448                            0.000000  ...            845.495514   \n",
       "57449                            0.000000  ...              0.000000   \n",
       "57450                            0.000000  ...            342.132089   \n",
       "\n",
       "       damageSelfMitigated_9_s  damageDealtToTurrets_9_s  turretsLost_9_s  \\\n",
       "0                   324.566879                 76.928818         0.102803   \n",
       "1                   738.315027                 13.437196         0.224642   \n",
       "2                     0.000000                  0.000000         0.000000   \n",
       "3                   523.134053                 27.740439         0.152885   \n",
       "4                  1011.594398                 34.129517         0.222025   \n",
       "...                        ...                       ...              ...   \n",
       "57446               209.247839                 34.297628         0.183640   \n",
       "57447               618.165555                 12.523118         0.193511   \n",
       "57448               207.942847                 20.437388         0.172670   \n",
       "57449                 0.000000                  0.000000         0.000000   \n",
       "57450               502.376201                  3.651912         0.193365   \n",
       "\n",
       "       totalTimeCCDealt_9_s  totalDamageTaken_9_s  \\\n",
       "0                 10.181232            433.579509   \n",
       "1                  1.839656            529.999910   \n",
       "2                  0.000000              0.000000   \n",
       "3                  2.118536            516.618493   \n",
       "4                  3.620328            905.347510   \n",
       "...                     ...                   ...   \n",
       "57446              6.281197            399.385287   \n",
       "57447              7.876048            451.764455   \n",
       "57448              5.299503            526.386009   \n",
       "57449              0.000000              0.000000   \n",
       "57450              4.317972            623.992657   \n",
       "\n",
       "       visionWardsBoughtInGame_9_s  physicalDamageDealt_9_s  win    Set  \n",
       "0                         0.153529               178.532931    0  train  \n",
       "1                         0.137576               151.173466    0  train  \n",
       "2                         0.000000                 0.000000    0  train  \n",
       "3                         0.380332               207.602800    1  train  \n",
       "4                         0.069698                71.321709    0  train  \n",
       "...                            ...                      ...  ...    ...  \n",
       "57446                     0.202918               177.018736    1   test  \n",
       "57447                     0.335950               288.089896    0   test  \n",
       "57448                     0.244624               122.823517    0   test  \n",
       "57449                     0.000000                 0.000000    1   test  \n",
       "57450                     0.344983               210.375273    0   test  \n",
       "\n",
       "[287256 rows x 352 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'train'\n",
    "# out = Path(os.getcwd()+'/data/'+dataset_name+'.csv')\n",
    "\n",
    "# label_name = 'LABEL_mastery_and_win_rate'\n",
    "# label_path = Path(os.getcwd()+'/data/'+label_name+'.csv')\n",
    "\n",
    "# test_dataset_name = 'test'\n",
    "# test_out = Path(os.getcwd()+'/data/'+test_dataset_name+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(label_path, 'r', encoding='UTF8') as f:\n",
    "#     raw_labels = f.readlines()\n",
    "\n",
    "# label_dict={}\n",
    "# win_idx = raw_labels[0].split(',').index('_win_0_l')\n",
    "# matchid_idx = raw_labels[0].split(',').index('_matchId\\n')\n",
    "# for raw_label in raw_labels[1:]:\n",
    "#     raw_label = raw_label.split(',')\n",
    "#     label_dict[raw_label[matchid_idx].strip()] = int(raw_label[win_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(out)\n",
    "#train.rename(columns = {'_matchId': 'win'}, inplace = True)\n",
    "#train['win'] = train['win'].map(lambda x: label_dict[x])\n",
    "target = 'win'\n",
    "# if \"Set\" not in train.columns:\n",
    "#     train[\"Set\"] = np.random.choice([\"train\", \"valid\"], p =[.9, .1], size=(train.shape[0],))\n",
    "\n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index\n",
    "test_indices = train[train.Set==\"test\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv(test_out)\n",
    "#train.rename(columns = {'_matchId': 'win'}, inplace = True)\n",
    "#train['win'] = train['win'].map(lambda x: label_dict[x])\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(out)\n",
    "# label = pd.read_csv(label_path)\n",
    "# train = pd.concat([train, label], axis=1)\n",
    "# train.rename(columns = {'win_100': 'win'}, inplace = True)\n",
    "# target = 'win'\n",
    "# if \"Set\" not in train.columns:\n",
    "#     train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "# train_indices = train[train.Set==\"train\"].index\n",
    "# valid_indices = train[train.Set==\"valid\"].index\n",
    "# test_indices = train[train.Set==\"test\"].index\n",
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simple preprocessing\n",
    "\n",
    "Label encode categorical features and fill empty cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win 2\n",
      "Set 3\n"
     ]
    }
   ],
   "source": [
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in train.columns:\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        train[col] = train[col].fillna(\"VV_likely\")\n",
    "        train[col] = l_enc.fit_transform(train[col].values)\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        train.fillna(train.loc[train_indices, col].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['win', 'Set']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'win': 2, 'Set': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that pipeline accepts strings\n",
    "train.loc[train[target]==0, target] = \"lose\"\n",
    "train.loc[train[target]==1, target] = \"win\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define categorical features for categorical embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Set']\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat+[target]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/tabnet/pytorch_tabnet/abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\"cat_idxs\":cat_idxs,\n",
    "                 \"cat_dims\":cat_dims,\n",
    "                 \"cat_emb_dim\":1,\n",
    "                 \"optimizer_fn\":torch.optim.Adam,\n",
    "                 \"optimizer_params\":dict(lr=2e-2),\n",
    "                 \"scheduler_params\":{\"step_size\":10, # how to use learning rate scheduler\n",
    "                                 \"gamma\":0.9},\n",
    "                 \"scheduler_fn\":torch.optim.lr_scheduler.StepLR,\n",
    "                 \"mask_type\":'sparsemax' # \"sparsemax, entmax\"\n",
    "                }\n",
    "\n",
    "clf = TabNetClassifier(**tabnet_params\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features].values[train_indices]\n",
    "y_train = train[target].values[train_indices]\n",
    "\n",
    "X_valid = train[features].values[valid_indices]\n",
    "y_valid = train[target].values[valid_indices]\n",
    "\n",
    "X_test = train[features].values[test_indices]\n",
    "y_test = train[target].values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 1000 if not os.getenv(\"CI\", False) else 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.69681 | train_accuracy: 0.51064 | valid_accuracy: 0.51151 |  0:00:20s\n",
      "epoch 1  | loss: 0.69216 | train_accuracy: 0.52488 | valid_accuracy: 0.52527 |  0:00:40s\n",
      "epoch 2  | loss: 0.69139 | train_accuracy: 0.52216 | valid_accuracy: 0.52073 |  0:01:00s\n",
      "epoch 3  | loss: 0.68997 | train_accuracy: 0.53888 | valid_accuracy: 0.53789 |  0:01:21s\n",
      "epoch 4  | loss: 0.68844 | train_accuracy: 0.5433  | valid_accuracy: 0.54512 |  0:01:40s\n",
      "epoch 5  | loss: 0.68813 | train_accuracy: 0.54447 | valid_accuracy: 0.54432 |  0:02:00s\n",
      "epoch 6  | loss: 0.68723 | train_accuracy: 0.5482  | valid_accuracy: 0.54966 |  0:02:19s\n",
      "epoch 7  | loss: 0.68705 | train_accuracy: 0.54954 | valid_accuracy: 0.55105 |  0:02:40s\n",
      "epoch 8  | loss: 0.68649 | train_accuracy: 0.54909 | valid_accuracy: 0.55004 |  0:03:00s\n",
      "epoch 9  | loss: 0.68614 | train_accuracy: 0.54998 | valid_accuracy: 0.54969 |  0:03:19s\n",
      "epoch 10 | loss: 0.68564 | train_accuracy: 0.55212 | valid_accuracy: 0.55394 |  0:03:40s\n",
      "epoch 11 | loss: 0.68562 | train_accuracy: 0.55371 | valid_accuracy: 0.55586 |  0:04:00s\n",
      "epoch 12 | loss: 0.68523 | train_accuracy: 0.55577 | valid_accuracy: 0.55641 |  0:04:21s\n",
      "epoch 13 | loss: 0.68495 | train_accuracy: 0.55423 | valid_accuracy: 0.55589 |  0:04:41s\n",
      "epoch 14 | loss: 0.68433 | train_accuracy: 0.55559 | valid_accuracy: 0.55774 |  0:05:01s\n",
      "epoch 15 | loss: 0.68389 | train_accuracy: 0.55696 | valid_accuracy: 0.55834 |  0:05:21s\n",
      "epoch 16 | loss: 0.68388 | train_accuracy: 0.55528 | valid_accuracy: 0.55693 |  0:05:42s\n",
      "epoch 17 | loss: 0.68346 | train_accuracy: 0.55475 | valid_accuracy: 0.55615 |  0:06:03s\n",
      "epoch 18 | loss: 0.68443 | train_accuracy: 0.55677 | valid_accuracy: 0.55885 |  0:06:24s\n",
      "epoch 19 | loss: 0.68336 | train_accuracy: 0.55669 | valid_accuracy: 0.5593  |  0:06:44s\n",
      "epoch 20 | loss: 0.68391 | train_accuracy: 0.55789 | valid_accuracy: 0.55927 |  0:07:05s\n",
      "epoch 21 | loss: 0.68243 | train_accuracy: 0.56139 | valid_accuracy: 0.56325 |  0:07:25s\n",
      "epoch 22 | loss: 0.68325 | train_accuracy: 0.55784 | valid_accuracy: 0.55942 |  0:07:45s\n",
      "epoch 23 | loss: 0.68312 | train_accuracy: 0.56232 | valid_accuracy: 0.56531 |  0:08:04s\n",
      "epoch 24 | loss: 0.68183 | train_accuracy: 0.56219 | valid_accuracy: 0.56505 |  0:08:24s\n",
      "epoch 25 | loss: 0.68175 | train_accuracy: 0.56025 | valid_accuracy: 0.56174 |  0:08:45s\n",
      "epoch 26 | loss: 0.68063 | train_accuracy: 0.56325 | valid_accuracy: 0.56585 |  0:09:05s\n",
      "epoch 27 | loss: 0.68025 | train_accuracy: 0.56494 | valid_accuracy: 0.56524 |  0:09:24s\n",
      "epoch 28 | loss: 0.68104 | train_accuracy: 0.56642 | valid_accuracy: 0.568   |  0:09:44s\n",
      "epoch 29 | loss: 0.68132 | train_accuracy: 0.56795 | valid_accuracy: 0.57018 |  0:10:04s\n",
      "epoch 30 | loss: 0.67985 | train_accuracy: 0.56718 | valid_accuracy: 0.56992 |  0:10:25s\n",
      "epoch 31 | loss: 0.67749 | train_accuracy: 0.57252 | valid_accuracy: 0.57485 |  0:10:45s\n",
      "epoch 32 | loss: 0.6774  | train_accuracy: 0.56989 | valid_accuracy: 0.57222 |  0:11:06s\n",
      "epoch 33 | loss: 0.67817 | train_accuracy: 0.57363 | valid_accuracy: 0.5766  |  0:11:26s\n",
      "epoch 34 | loss: 0.67714 | train_accuracy: 0.57511 | valid_accuracy: 0.57634 |  0:11:46s\n",
      "epoch 35 | loss: 0.67663 | train_accuracy: 0.56963 | valid_accuracy: 0.57109 |  0:12:07s\n",
      "epoch 36 | loss: 0.67682 | train_accuracy: 0.57515 | valid_accuracy: 0.57585 |  0:12:27s\n",
      "epoch 37 | loss: 0.6765  | train_accuracy: 0.57902 | valid_accuracy: 0.58054 |  0:12:48s\n",
      "epoch 38 | loss: 0.67508 | train_accuracy: 0.58066 | valid_accuracy: 0.58235 |  0:13:09s\n",
      "epoch 39 | loss: 0.67429 | train_accuracy: 0.57912 | valid_accuracy: 0.58207 |  0:13:29s\n",
      "epoch 40 | loss: 0.67362 | train_accuracy: 0.58193 | valid_accuracy: 0.58524 |  0:13:50s\n",
      "epoch 41 | loss: 0.67399 | train_accuracy: 0.58271 | valid_accuracy: 0.58491 |  0:14:10s\n",
      "epoch 42 | loss: 0.6724  | train_accuracy: 0.58382 | valid_accuracy: 0.58677 |  0:14:31s\n",
      "epoch 43 | loss: 0.67191 | train_accuracy: 0.58616 | valid_accuracy: 0.58645 |  0:14:52s\n",
      "epoch 44 | loss: 0.67217 | train_accuracy: 0.58682 | valid_accuracy: 0.5882  |  0:15:12s\n",
      "epoch 45 | loss: 0.67097 | train_accuracy: 0.58847 | valid_accuracy: 0.58978 |  0:15:33s\n",
      "epoch 46 | loss: 0.67127 | train_accuracy: 0.58962 | valid_accuracy: 0.58914 |  0:15:54s\n",
      "epoch 47 | loss: 0.66967 | train_accuracy: 0.591   | valid_accuracy: 0.59102 |  0:16:13s\n",
      "epoch 48 | loss: 0.67002 | train_accuracy: 0.58898 | valid_accuracy: 0.58898 |  0:16:34s\n",
      "epoch 49 | loss: 0.66992 | train_accuracy: 0.59117 | valid_accuracy: 0.5922  |  0:16:53s\n",
      "epoch 50 | loss: 0.66919 | train_accuracy: 0.59296 | valid_accuracy: 0.5934  |  0:17:14s\n",
      "epoch 51 | loss: 0.6677  | train_accuracy: 0.59407 | valid_accuracy: 0.59366 |  0:17:33s\n",
      "epoch 52 | loss: 0.6688  | train_accuracy: 0.5956  | valid_accuracy: 0.59632 |  0:17:54s\n",
      "epoch 53 | loss: 0.66895 | train_accuracy: 0.59505 | valid_accuracy: 0.59674 |  0:18:14s\n",
      "epoch 54 | loss: 0.66555 | train_accuracy: 0.59798 | valid_accuracy: 0.59845 |  0:18:34s\n",
      "epoch 55 | loss: 0.66523 | train_accuracy: 0.59944 | valid_accuracy: 0.60076 |  0:18:55s\n",
      "epoch 56 | loss: 0.66617 | train_accuracy: 0.59816 | valid_accuracy: 0.6     |  0:19:15s\n",
      "epoch 57 | loss: 0.6645  | train_accuracy: 0.5996  | valid_accuracy: 0.60108 |  0:19:36s\n",
      "epoch 58 | loss: 0.66459 | train_accuracy: 0.60219 | valid_accuracy: 0.60196 |  0:19:55s\n",
      "epoch 59 | loss: 0.66436 | train_accuracy: 0.60347 | valid_accuracy: 0.60468 |  0:20:16s\n",
      "epoch 60 | loss: 0.66294 | train_accuracy: 0.60425 | valid_accuracy: 0.60489 |  0:20:36s\n",
      "epoch 61 | loss: 0.66194 | train_accuracy: 0.60378 | valid_accuracy: 0.60395 |  0:20:57s\n",
      "epoch 62 | loss: 0.66176 | train_accuracy: 0.60248 | valid_accuracy: 0.6035  |  0:21:17s\n",
      "epoch 63 | loss: 0.66248 | train_accuracy: 0.6059  | valid_accuracy: 0.60793 |  0:21:37s\n",
      "epoch 64 | loss: 0.66185 | train_accuracy: 0.60798 | valid_accuracy: 0.60908 |  0:21:56s\n",
      "epoch 65 | loss: 0.66134 | train_accuracy: 0.60857 | valid_accuracy: 0.6096  |  0:22:16s\n",
      "epoch 66 | loss: 0.65972 | train_accuracy: 0.61098 | valid_accuracy: 0.61178 |  0:22:36s\n",
      "epoch 67 | loss: 0.65922 | train_accuracy: 0.60879 | valid_accuracy: 0.60967 |  0:22:57s\n",
      "epoch 68 | loss: 0.65921 | train_accuracy: 0.60876 | valid_accuracy: 0.61028 |  0:23:17s\n",
      "epoch 69 | loss: 0.66109 | train_accuracy: 0.61243 | valid_accuracy: 0.61241 |  0:23:37s\n",
      "epoch 70 | loss: 0.65868 | train_accuracy: 0.61246 | valid_accuracy: 0.61152 |  0:23:57s\n",
      "epoch 71 | loss: 0.65903 | train_accuracy: 0.6068  | valid_accuracy: 0.60776 |  0:24:18s\n",
      "epoch 72 | loss: 0.65911 | train_accuracy: 0.61351 | valid_accuracy: 0.61479 |  0:24:38s\n",
      "epoch 73 | loss: 0.65687 | train_accuracy: 0.61332 | valid_accuracy: 0.61298 |  0:24:59s\n",
      "epoch 74 | loss: 0.65744 | train_accuracy: 0.61434 | valid_accuracy: 0.61467 |  0:25:20s\n",
      "epoch 75 | loss: 0.65779 | train_accuracy: 0.61588 | valid_accuracy: 0.61624 |  0:25:40s\n",
      "epoch 76 | loss: 0.65552 | train_accuracy: 0.61607 | valid_accuracy: 0.61702 |  0:26:01s\n",
      "epoch 77 | loss: 0.65705 | train_accuracy: 0.61673 | valid_accuracy: 0.61796 |  0:26:22s\n",
      "epoch 78 | loss: 0.65692 | train_accuracy: 0.61711 | valid_accuracy: 0.61737 |  0:26:42s\n",
      "epoch 79 | loss: 0.65499 | train_accuracy: 0.61654 | valid_accuracy: 0.61697 |  0:27:03s\n",
      "epoch 80 | loss: 0.65503 | train_accuracy: 0.61811 | valid_accuracy: 0.61826 |  0:27:25s\n",
      "epoch 81 | loss: 0.65482 | train_accuracy: 0.6202  | valid_accuracy: 0.62104 |  0:27:47s\n",
      "epoch 82 | loss: 0.65401 | train_accuracy: 0.62203 | valid_accuracy: 0.62496 |  0:28:07s\n",
      "epoch 83 | loss: 0.65491 | train_accuracy: 0.62229 | valid_accuracy: 0.62212 |  0:28:27s\n",
      "epoch 84 | loss: 0.6535  | train_accuracy: 0.62105 | valid_accuracy: 0.62134 |  0:28:48s\n",
      "epoch 85 | loss: 0.6538  | train_accuracy: 0.62288 | valid_accuracy: 0.6252  |  0:29:10s\n",
      "epoch 86 | loss: 0.65365 | train_accuracy: 0.62206 | valid_accuracy: 0.62247 |  0:29:33s\n",
      "epoch 87 | loss: 0.65226 | train_accuracy: 0.62275 | valid_accuracy: 0.62327 |  0:29:57s\n",
      "epoch 88 | loss: 0.65273 | train_accuracy: 0.6236  | valid_accuracy: 0.62442 |  0:30:21s\n",
      "epoch 89 | loss: 0.65316 | train_accuracy: 0.6241  | valid_accuracy: 0.62393 |  0:30:45s\n",
      "epoch 90 | loss: 0.65099 | train_accuracy: 0.62635 | valid_accuracy: 0.62722 |  0:31:07s\n",
      "epoch 91 | loss: 0.65224 | train_accuracy: 0.62603 | valid_accuracy: 0.62769 |  0:31:30s\n",
      "epoch 92 | loss: 0.65105 | train_accuracy: 0.62693 | valid_accuracy: 0.62752 |  0:31:52s\n",
      "epoch 93 | loss: 0.64934 | train_accuracy: 0.62659 | valid_accuracy: 0.62812 |  0:32:14s\n",
      "epoch 94 | loss: 0.65189 | train_accuracy: 0.62424 | valid_accuracy: 0.62423 |  0:32:36s\n",
      "epoch 95 | loss: 0.65152 | train_accuracy: 0.62611 | valid_accuracy: 0.62668 |  0:32:58s\n",
      "epoch 96 | loss: 0.65123 | train_accuracy: 0.62762 | valid_accuracy: 0.62807 |  0:33:19s\n",
      "epoch 97 | loss: 0.64996 | train_accuracy: 0.6276  | valid_accuracy: 0.62637 |  0:33:42s\n",
      "epoch 98 | loss: 0.65001 | train_accuracy: 0.62945 | valid_accuracy: 0.62966 |  0:34:02s\n",
      "epoch 99 | loss: 0.64971 | train_accuracy: 0.62836 | valid_accuracy: 0.62847 |  0:34:34s\n",
      "epoch 100| loss: 0.64916 | train_accuracy: 0.62962 | valid_accuracy: 0.63105 |  0:35:06s\n",
      "epoch 101| loss: 0.64986 | train_accuracy: 0.62953 | valid_accuracy: 0.63087 |  0:35:40s\n",
      "epoch 102| loss: 0.64927 | train_accuracy: 0.62981 | valid_accuracy: 0.62955 |  0:36:14s\n",
      "epoch 103| loss: 0.64935 | train_accuracy: 0.63249 | valid_accuracy: 0.63159 |  0:36:47s\n",
      "epoch 104| loss: 0.6482  | train_accuracy: 0.63047 | valid_accuracy: 0.62999 |  0:37:21s\n",
      "epoch 105| loss: 0.64898 | train_accuracy: 0.63211 | valid_accuracy: 0.633   |  0:37:54s\n",
      "epoch 106| loss: 0.6459  | train_accuracy: 0.63123 | valid_accuracy: 0.63039 |  0:38:28s\n",
      "epoch 107| loss: 0.64788 | train_accuracy: 0.63063 | valid_accuracy: 0.63032 |  0:39:00s\n",
      "epoch 108| loss: 0.64879 | train_accuracy: 0.63227 | valid_accuracy: 0.63244 |  0:39:33s\n",
      "epoch 109| loss: 0.64822 | train_accuracy: 0.6326  | valid_accuracy: 0.63342 |  0:40:06s\n",
      "epoch 110| loss: 0.6484  | train_accuracy: 0.63331 | valid_accuracy: 0.6327  |  0:40:38s\n",
      "epoch 111| loss: 0.6467  | train_accuracy: 0.63533 | valid_accuracy: 0.63503 |  0:41:13s\n",
      "epoch 112| loss: 0.64719 | train_accuracy: 0.63421 | valid_accuracy: 0.63516 |  0:41:47s\n",
      "epoch 113| loss: 0.64652 | train_accuracy: 0.63421 | valid_accuracy: 0.63448 |  0:42:22s\n",
      "epoch 114| loss: 0.64687 | train_accuracy: 0.63579 | valid_accuracy: 0.63589 |  0:42:55s\n"
     ]
    }
   ],
   "source": [
    "# This illustrates the warm_start=False behaviour\n",
    "save_history = []\n",
    "for _ in range(2):\n",
    "    clf.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "        eval_name=['train', 'valid'],\n",
    "        eval_metric=['accuracy'],\n",
    "        max_epochs=max_epochs , patience=50,\n",
    "        batch_size=1024, virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        weights=1,\n",
    "        drop_last=False\n",
    "    )\n",
    "    save_history.append(clf.history[\"valid_accuracy\"])\n",
    "    \n",
    "assert(np.all(np.array(save_history[0]==np.array(save_history[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc\n",
    "plt.plot(clf.history['train_accuracy'])\n",
    "plt.plot(clf.history['valid_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning rates\n",
    "plt.plot(clf.history['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)\n",
    "test_acc = accuracy_score(y_true=[0 if x =='lose' else 1 for x in y_test ], y_pred=[0 if x < 0.5 else 1 for x in preds[:,1]])\n",
    "\n",
    "preds_valid = clf.predict_proba(X_valid)\n",
    "valid_acc = accuracy_score(y_true=[0 if x =='lose' else 1 for x in y_valid ], y_pred=[0 if x < 0.5 else 1 for x in preds_valid[:,1]])\n",
    "print(f\"BEST VALID SCORE FOR {dataset_name} : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR {dataset_name} : {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that best weights are used\n",
    "assert np.isclose(valid_acc, np.max(clf.history['valid_accuracy']), atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tabnet model\n",
    "saving_path_name = \"./tabnet_model_test_1\"\n",
    "saved_filepath = clf.save_model(saving_path_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new model with basic parameters and load state dict weights\n",
    "loaded_clf = TabNetClassifier()\n",
    "loaded_clf.load_model(saved_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_preds = loaded_clf.predict_proba(X_test)\n",
    "loaded_test_acc = accuracy_score(y_true=[0 if x =='lose' else 1 for x in y_test ], y_pred=[0 if x < 0.5 else 1 for x in loaded_preds[:,1]])\n",
    "print(f\"FINAL TEST SCORE FOR {dataset_name} : {loaded_test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(test_acc == loaded_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global explainability : feat importance summing to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local explainability and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_matrix, masks = clf.explain(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,20))\n",
    "\n",
    "for i in range(3):\n",
    "    axs[i].imshow(masks[i][:50])\n",
    "    axs[i].set_title(f\"mask {i}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_xgb = XGBClassifier(max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000,\n",
    "    verbosity=0,\n",
    "    silent=None,\n",
    "    objective='binary:logistic',\n",
    "    booster='gbtree',\n",
    "    n_jobs=-1,\n",
    "    nthread=None,\n",
    "    gamma=0,\n",
    "    min_child_weight=1,\n",
    "    max_delta_step=0,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=1,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    base_score=0.5,\n",
    "    random_state=0,\n",
    "    seed=None,)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(clf_xgb.predict_proba(X_valid))\n",
    "valid_acc = accuracy_score(y_true= [0 if x =='lose' else 1 for x in y_valid ], y_pred=[0 if x < 0.5 else 1 for x in preds[:,1]])\n",
    "print(valid_acc)\n",
    "\n",
    "preds = np.array(clf_xgb.predict_proba(X_test))\n",
    "test_acc = accuracy_score(y_true=[0 if x =='lose' else 1 for x in y_test ], y_pred=[0 if x < 0.5 else 1 for x in preds[:,1]])\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
